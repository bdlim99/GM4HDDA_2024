{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 3, Programming Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we study a Riemannian geometric structure for the space of point cloud data, based on the theory of statistical manifold and information geometry.   \n",
    "As an application, we conduct geodesic interpolation of point cloud using a latent representation from a pretrained point cloud autoencoder.    \n",
    "For details, you may refer to \\<A Statistical Manifold Framework for Point Cloud Data\\> (Yonghyeon Lee, Seungyeon Kim, Jinwon Choi, and Frack C. Park, ICML 2022).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Manifold Framework for Point Cloud Data\n",
    "A point cloud $X$ (with a fixed number of points, $n$) in $\\mathbb{R}^D$ can be represented as $X=\\{ x_1,\\ldots,x_n | x_i\\in\\mathbb{R}^D, x_i\\neq x_j \\text{ if } i\\neq j \\}$.   \n",
    "Given a point cloud $X$, a probability density function $p(x;X)$ parameterized by the point cloud can be defined as\n",
    "$$ p(x;X) = \\frac{1}{n\\sqrt{|\\Sigma|}} \\sum^n_{i=1}K(\\Sigma^{-1/2}(x-x_i)) \\quad\\text{where}\\quad \\Sigma=\\sigma^2 I, \\; K(u)=\\frac{1}{\\sqrt{(2\\pi)^D}}\\exp(-\\frac{u^Tu}{2}), $$\n",
    "which is just a kernel density estimate using a Gaussian kernel $K$ and an isotropic bandwidth matrix $\\Sigma$.   \n",
    "Let us denote the space of all point cloud data by ${\\cal X}$ and define ${\\cal S}:=\\{ p(x;X) | X\\in{\\cal X} \\}$.   \n",
    "Then, it can be known that the correspondence $X \\mapsto p(x;X)$ between the space of point clouds and the statistical manifold ${\\cal S}$ becomes a one-to-one mapping.   \n",
    "Since the statistical manifold ${\\cal S}$ has its natural Riemannian metric, namely the Fisher information metric, a Riemannian geometric structure of the space of point clouds is naturally defined as well.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"figures/pc_to_mfd.png\" alt=\"Point Cloud to Manifold Correspondence\" width=\"750\"/>\n",
    "</p>\n",
    "<p align=\"center\"><em>Figure 1: The statistical manifold obtained from the one-to-one mappting between point clouds and probabitliy density functions. </em></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Environment\n",
    "For this exercise, we need to setup the following environment\n",
    "- python 3.8\n",
    "- numpy\n",
    "- scipy\n",
    "- matplotlib\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- h5py\n",
    "- pyyaml\n",
    "- omegaconf\n",
    "- tqdm\n",
    "- torch, torchvision\n",
    "    - https://pytorch.org/get-started/locally/\n",
    "- [torchcubicspline](https://github.com/patrick-kidger/torchcubicspline)\n",
    "    - `pip install git+https://github.com/patrick-kidger/torchcubicspline.git`\n",
    "- Open3D 0.13.0\n",
    "    - `pip install open3d==0.13.0 --no-deps`\n",
    "    - **Warining:** The latest version of Open3D has slightly different syntax, so we highly recommend using the Open3D version of 0.13.0 as noted above.\n",
    "    - Use `--no-dpes` option to avoid installation errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "- Create `datasets/` directory.\n",
    "- Download `interpolation_dataset.zip` from the [Google drive link](https://drive.google.com/drive/folders/1NuGq2LtWG627r9BNPzb1EegUuIvPUzDr?usp=sharing), and unzip it under `datasets/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained Model\n",
    "- Create `pretrained/` directory.\n",
    "- Download `interpolation_config.zip` from the [Google drive link](https://drive.google.com/drive/folders/1NuYIfyU6kVQ09qPR6rONWrernKMps_FX?usp=sharing), and unzip it under `pretrained/` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torchcubicspline import(natural_cubic_spline_coeffs, \n",
    "                             NaturalCubicSpline)\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from loader import get_dataloader\n",
    "from models import load_pretrained\n",
    "\n",
    "from functions.util import label_to_color, figure_to_array\n",
    "from functions.color_assignment import latent_to_color\n",
    "from functions.util import gallery, render_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up Your Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a GPU, comment out the second line and uncomment the first line\n",
    "# If you don't have a GPU, comment out the first line and uncomment the second line\n",
    "\n",
    "####################### Change Device Here #######################\n",
    "device = 'cuda:0'\n",
    "# device = 'cpu'\n",
    "##################################################################\n",
    "\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained autoencoder\n",
    "config = ('interpolation_config/vanilla', 'interpolation_config.yml', 'model_best.pkl', {})\n",
    "root = 'pretrained/'\n",
    "\n",
    "# parameters\n",
    "num_interpolates_linear = 20\n",
    "num_interpolates_geodesic = num_interpolates_linear - 1\n",
    "k = 0.5   \n",
    "epoch_curve = 5000                                          # 5000 recommended for good results. Set to smaller values (e.g., 1500) if the computation takes too long (e.g., when using cpu).\n",
    "learning_rate = 1e-3\n",
    "num_samples = 40\n",
    "n_control_points = 10\n",
    "mode = 'smoothed_nn'\n",
    "\n",
    "# figure parameters\n",
    "scale = 0.02\n",
    "scale_ratio = 1.4\n",
    "kwargs_linear = {'linestyle': 'dotted', 'linewidth': 1.5, 'label': 'linear', 'c': [253/255, 134/255, 18/255]}\n",
    "kwargs_identity = {'linestyle': 'dashed', 'linewidth': 1.5, 'label': 'identity', 'c': [253/255, 134/255, 18/255]}\n",
    "kwargs_geodesic = {'linestyle': 'solid', 'linewidth': 1.5, 'label': 'geodesic', 'c': [253/255, 134/255, 18/255]}\n",
    "label_to_text = ['box', 'cylinder', 'cone', 'ellipsoid', 'interpolates']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "Z = []\n",
    "y = []\n",
    "P = []\n",
    "\n",
    "# load configuration \n",
    "identifier, config_file, ckpt_file, kwargs = config\n",
    "\n",
    "# load pretrained model\n",
    "kwargs = {}\n",
    "model, cfg = load_pretrained(identifier, config_file, ckpt_file, root=root, **kwargs)\n",
    "model.to(device)\n",
    "\n",
    "# load test data\n",
    "print(\"Load Test Data and Encode!\")\n",
    "cfg_test = cfg['data']['test']\n",
    "test_dl, mean_MED = get_dataloader(cfg_test)\n",
    "sample = 0\n",
    "for data in test_dl:\n",
    "    P.append(data[0].to(device))\n",
    "    Z.append(copy.copy(model.encode(data[0].to(device))))\n",
    "    y.append(data[1]) \n",
    "    sample += 1 \n",
    "P = torch.cat(P, dim=0)\n",
    "Z = torch.cat(Z, dim=0)\n",
    "y = torch.cat(y, dim=0)\n",
    "color_3d = label_to_color(y.squeeze().detach().cpu().numpy())\n",
    "print(f'Mean MED of the dataset is {mean_MED}.')\n",
    "\n",
    "# Latent Space Encoding \n",
    "f = plt.figure()\n",
    "plt.scatter(Z[:,0].detach().cpu(), Z[:,1].detach().cpu(), c=color_3d/255.0)\n",
    "plt.axis('equal')\n",
    "plt.close()\n",
    "f_np = np.transpose(figure_to_array(f), (2, 0, 1))\n",
    "\n",
    "# class-wise latent vectors\n",
    "Z_cylinder = Z[y.view(-1)==1].detach()\n",
    "Z_cone = Z[y.view(-1)==2].detach()\n",
    "z_list = []\n",
    "\n",
    "# interpolation candidates\n",
    "data_idx_list = [\n",
    "    [torch.argsort(Z_cylinder[:,0])[-15], torch.argsort(Z_cylinder[:,0])[1]],\n",
    "    [torch.argsort(Z_cone[:,0])[-1], torch.argsort(Z_cone[:,0])[0]],\n",
    "    [torch.argsort(Z_cylinder[:,0])[-185], torch.argsort(Z_cone[:,0])[-110]]\n",
    "]\n",
    "z_list.append([Z_cylinder[data_idx_list[0][0]], Z_cylinder[data_idx_list[0][1]]])\n",
    "z_list.append([Z_cone[data_idx_list[1][0]], Z_cone[data_idx_list[1][1]]])\n",
    "z_list.append([Z_cylinder[data_idx_list[2][0]], Z_cone[data_idx_list[2][1]]])\n",
    "\n",
    "# selected example\n",
    "z_ = z_list[0]\n",
    "z1 = z_[0]\n",
    "z2 = z_[1]        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Linear Interpolation\n",
    "Conduct linear interpolation in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Your Code Here ###########################\n",
    "# TO DO: Linearly interpolate between z1 and z2.\n",
    "# z_linear_interpolates should be a (num_interpolates_linear, 2)-shaped tensor\n",
    "\n",
    "# z_linear_interpolates = ##### Your Code Here #####\n",
    "\n",
    "###################################################################\n",
    "x_linear_interpolates = model.decode(z_linear_interpolates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space visualization - linear interpolation\n",
    "f = plt.figure()\n",
    "plt.scatter(Z[:,0].detach().cpu(), Z[:,1].detach().cpu(), c=color_3d/255.0)\n",
    "plt.scatter(z1[0].detach().cpu(), z1[1].detach().cpu(), c='r', marker='*', s=200)\n",
    "plt.scatter(z2[0].detach().cpu(), z2[1].detach().cpu(), c='r', marker='*', s=200)\n",
    "plt.plot(\n",
    "    z_linear_interpolates[:, 0].detach().cpu(), \n",
    "    z_linear_interpolates[:, 1].detach().cpu(), \n",
    "    c='k',\n",
    "    linewidth=3.0\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Cubic Spline Optimizer for Geodesic Computation\n",
    "On the latent space of the pretrained point cloud autoencoder, a geodesic curve can be obtained by optimizing an appropriate objective function.   \n",
    "For this, we define `cubic_spline_curve` class, whose `train_step` returns the objective function for geodesic and `compute_length` the (Riemannian) length of a spline curve.   \n",
    "For your information, the definitions of `get_Identity_proj_Riemannian_metric` and `get_Fisher_proj_Riemannian_metric` can be found in `models/base_arch.py`.   \n",
    "These compute the projection of Euclidean metric and Fisher information metric onto the latent space through decoder Jacobian.   \n",
    "Complete `train_step` and `compute_length`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cubic_spline_curve(torch.nn.Module):\n",
    "    def __init__(self, z_i, z_f, mean_MED, k, device, metric_type, channels=2, lengths=2):\n",
    "        super(cubic_spline_curve, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.z_i = z_i.unsqueeze(0)\n",
    "        self.z_f = z_f.unsqueeze(0)\n",
    "        self.mean_MED = mean_MED\n",
    "        self.k = k\n",
    "        self.device = device\n",
    "        self.metric_type = metric_type\n",
    "        self.z = Parameter(\n",
    "                    torch.cat(\n",
    "                        [self.z_i + (self.z_f-self.z_i) * t / (lengths + 1) + torch.randn_like(self.z_i)*0.0 for t in range(1, lengths+1)], dim=0)\n",
    "        )\n",
    "        self.t_linspace = torch.linspace(0, 1, lengths + 2).to(self.device)\n",
    "\n",
    "    def append(self):\n",
    "        return torch.cat([self.z_i, self.z, self.z_f], dim=0)\n",
    "    \n",
    "    def spline_gen(self):\n",
    "        coeffs = natural_cubic_spline_coeffs(self.t_linspace, self.append())\n",
    "        spline = NaturalCubicSpline(coeffs)\n",
    "        return spline\n",
    "    \n",
    "    def forward(self, t):\n",
    "        out = self.spline_gen().evaluate(t)\n",
    "        return out\n",
    "    \n",
    "    def velocity(self, t):\n",
    "        out = self.spline_gen().derivative(t)\n",
    "        return out\n",
    "    \n",
    "    def train_step(self, model, num_samples):\n",
    "        t_samples = torch.rand(num_samples).to(self.device)\n",
    "        z_samples = self(t_samples)\n",
    "        if self.metric_type == 'identity':\n",
    "            G = model.get_Identity_proj_Riemannian_metric(z_samples, create_graph=True)\n",
    "        elif self.metric_type == 'information':\n",
    "            G = model.get_Fisher_proj_Riemannian_metric(\n",
    "                    z_samples, create_graph=True, sigma=self.mean_MED * self.k)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        z_dot_samples = self.velocity(t_samples)\n",
    "        ######################## Your Code Here ###########################\n",
    "        # TO DO: Define the loss function for the geodesic computation, using the Riemannian metrics G obtained above.\n",
    "        # geodesic_loss should be a tensor consiting of a single real number.\n",
    "        \n",
    "        # geodesic_loss = ##### Your Code Here #####\n",
    "        \n",
    "        ###################################################################\n",
    "        return geodesic_loss\n",
    "\n",
    "    def compute_length(self, model, num_discretizations=100):\n",
    "        t_samples = torch.linspace(0, 1, num_discretizations).to(self.device)\n",
    "        z_samples = self(t_samples)\n",
    "        if self.metric_type == 'identity':\n",
    "            G = model.get_Identity_proj_Riemannian_metric(z_samples, create_graph=False)\n",
    "        elif self.metric_type == 'information':\n",
    "            G = model.get_Fisher_proj_Riemannian_metric(\n",
    "                    z_samples, create_graph=False, sigma=self.mean_MED * self.k)\n",
    "        ######################## Your Code Here ###########################\n",
    "        # TO DO: Compute the (Riemannian) length of the curve, using the Riemannian metrics G obtained above.\n",
    "        # length should be a tensor consiting of a single real number.\n",
    "        \n",
    "        # length = ##### Your Code Here #####\n",
    "        \n",
    "        ###################################################################\n",
    "        return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geodesic Interpolation with Euclidean Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define curve and optimizer\n",
    "model_curve_identity = cubic_spline_curve(z1, z2, mean_MED, k, device, 'identity', lengths = n_control_points).to(device)\n",
    "optimizer = torch.optim.Adam(model_curve_identity.parameters(), lr=learning_rate)\n",
    "for epoch in range(epoch_curve):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model_curve_identity.train_step(model, num_samples)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        length = model_curve_identity.compute_length(model)\n",
    "        print(f'(identity_geodesic) Epoch {epoch}: loss = {loss.item()}: length = {length}')\n",
    "t_samples = torch.linspace(0, 1, steps=20).to(device)\n",
    "z_identity_interpolates = model_curve_identity(t_samples).detach().cpu()\n",
    "x_identity_interpolates = model.decode(z_identity_interpolates.to(torch.float32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space visualization - geodesic interpolation with Euclidean metric \n",
    "f = plt.figure()\n",
    "plt.scatter(Z[:,0].detach().cpu(), Z[:,1].detach().cpu(), c=color_3d/255.0)\n",
    "plt.scatter(z1[0].detach().cpu(), z1[1].detach().cpu(), c='r', marker='*', s=200)\n",
    "plt.scatter(z2[0].detach().cpu(), z2[1].detach().cpu(), c='r', marker='*', s=200)\n",
    "plt.plot(\n",
    "    z_identity_interpolates[:, 0].detach().cpu(), \n",
    "    z_identity_interpolates[:, 1].detach().cpu(), \n",
    "    c='k',\n",
    "    linewidth=3.0\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geodesic Interpolation with Fisher Information Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define curve and optimizer\n",
    "model_curve = cubic_spline_curve(z1, z2, mean_MED, k, device, 'information', lengths = n_control_points).to(device)\n",
    "optimizer = torch.optim.Adam(model_curve.parameters(), lr=learning_rate)\n",
    "\n",
    "# This part might take a while when using CPU (10~20 mins)\n",
    "for epoch in range(epoch_curve):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model_curve.train_step(model, num_samples)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        length = model_curve.compute_length(model)\n",
    "        print(f'(information_geodesic) Epoch {epoch}: loss = {loss.item()}: length = {length}')\n",
    "t_samples = torch.linspace(0, 1, steps=20).to(device)\n",
    "z_information_interpolates = model_curve(t_samples).detach().cpu()\n",
    "x_information_interpolates = model.decode(z_information_interpolates.to(torch.float32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space visualization - geodesic interpolation with Fisher information metric\n",
    "f = plt.figure()\n",
    "plt.scatter(Z[:,0].detach().cpu(), Z[:,1].detach().cpu(), c=color_3d/255.0)\n",
    "plt.scatter(z1[0].detach().cpu(), z1[1].detach().cpu(), c='r', marker='*', s=200)\n",
    "plt.scatter(z2[0].detach().cpu(), z2[1].detach().cpu(), c='r', marker='*', s=200)\n",
    "plt.plot(\n",
    "    z_information_interpolates[:, 0].detach().cpu(), \n",
    "    z_information_interpolates[:, 1].detach().cpu(), \n",
    "    c='k',\n",
    "    linewidth=3.0\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Can you interpret the latent space geodesics?\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Results as Point Clouds\n",
    "Using the decoder of the point cloud autoencoder, we will visualize the obtained interpolation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coloring\n",
    "color_linear_interp = latent_to_color(model, P, y, z_linear_interpolates.to(torch.float32).to(device), mode=mode)\n",
    "color_identity_interp = latent_to_color(model, P, y, z_identity_interpolates.to(torch.float32).to(device), mode=mode)\n",
    "color_information_interp = latent_to_color(model, P, y, z_information_interpolates.to(torch.float32).to(device), mode=mode)\n",
    "\n",
    "# initialize\n",
    "data_vis = dict()\n",
    "\n",
    "# save point clouds               \n",
    "data_vis['linear_interpolation'] = dict()\n",
    "data_vis['identity_interpolation'] = dict()\n",
    "data_vis['information_interpolation'] = dict()\n",
    "data_vis['linear_interpolation']['pc'] = []\n",
    "data_vis['linear_interpolation']['color'] = []\n",
    "data_vis['identity_interpolation']['pc'] = []\n",
    "data_vis['identity_interpolation']['color'] = []\n",
    "data_vis['information_interpolation']['pc'] = []\n",
    "data_vis['information_interpolation']['color'] = []\n",
    "for pidx in range(num_interpolates_linear):\n",
    "    data_vis['linear_interpolation']['pc'].append(np.asarray(x_linear_interpolates[pidx,:,:].detach().cpu()))\n",
    "    data_vis['identity_interpolation']['pc'].append(np.asarray(x_identity_interpolates[pidx,:,:].detach().cpu()))\n",
    "    data_vis['information_interpolation']['pc'].append(np.asarray(x_information_interpolates[pidx,:,:].detach().cpu()))\n",
    "    data_vis['linear_interpolation']['color'].append(np.repeat(color_linear_interp[pidx:pidx+1,:].transpose(), x_linear_interpolates.shape[2], axis=1))\n",
    "    data_vis['identity_interpolation']['color'].append(np.repeat(color_identity_interp[pidx:pidx+1,:].transpose(), x_identity_interpolates.shape[2], axis=1))\n",
    "    data_vis['information_interpolation']['color'].append(np.repeat(color_information_interp[pidx:pidx+1,:].transpose(), x_information_interpolates.shape[2], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for saving images\n",
    "folder_temp = 'interpolation_results/temp'\n",
    "if not os.path.exists(folder_temp):\n",
    "    os.makedirs(folder_temp)   \n",
    "\n",
    "# ball configuration\n",
    "radius = 0.03\n",
    "resolution = 20\n",
    "\n",
    "# image resolution\n",
    "img_width = 640\n",
    "img_height = 900\n",
    "\n",
    "# make point cloud mesh\n",
    "meshes_data = []\n",
    "meshes_for_finding_pose = []\n",
    "exp_name_list = []\n",
    "\n",
    "for l, idx_data_ in enumerate(data_vis.keys()):\n",
    "    exp_name_list.append(idx_data_)\n",
    "    data_ = data_vis[idx_data_]\n",
    "    points_list = data_['pc']\n",
    "    colors_list = data_['color']\n",
    "\n",
    "    for j in range(len(points_list)):\n",
    "        points = points_list[j].transpose()\n",
    "        colors = colors_list[j].transpose()\n",
    "\n",
    "        for i in range(len(points)):\n",
    "            mesh = o3d.geometry.TriangleMesh.create_sphere(radius = radius, resolution = resolution).translate((points[i,0], points[i,1], points[i,2]))\n",
    "            mesh.paint_uniform_color([colors[i,0]/255, colors[i,1]/255, colors[i,2]/255])\n",
    "            if i == 0:\n",
    "                mesh_total = mesh\n",
    "            else:\n",
    "                mesh_total += mesh\n",
    "        \n",
    "        mesh_total.compute_vertex_normals()\n",
    "        meshes_data.append(mesh_total)\n",
    "\n",
    "        if l == 0 and (j == 0 or j == len(points_list) - 1):\n",
    "            for i in range(len(points)):\n",
    "                mesh = o3d.geometry.TriangleMesh.create_sphere(radius = radius, resolution = resolution).translate((points[i,0], points[i,1], points[i,2]))\n",
    "                mesh.paint_uniform_color([colors[i,0]/255, colors[i,1]/255, colors[i,2]/255])\n",
    "                if i == 0:\n",
    "                    mesh_total = mesh\n",
    "                else:\n",
    "                    mesh_total += mesh\n",
    "        \n",
    "            mesh_total.compute_vertex_normals()\n",
    "            meshes_for_finding_pose.append(mesh_total)\n",
    "\n",
    "# save images\n",
    "for j in range(len(meshes_data)):\n",
    "    path_image = os.path.join(folder_temp, f'temp_{j}.png')\n",
    "    render_pointcloud(meshes_data[j], \n",
    "                    visualize=False, \n",
    "                    camera_config=None,\n",
    "                    return_camera_config=False,\n",
    "                    save_path=path_image,\n",
    "                    image_size = [img_width, img_height])\n",
    "\n",
    "# split\n",
    "splitedSize = 20\n",
    "meshes_data_splited = [meshes_data[x:x+splitedSize] for x in range(0, len(meshes_data), splitedSize)]\n",
    "\n",
    "# append images\n",
    "images = []\n",
    "counter = 0\n",
    "for k, split_ in enumerate(meshes_data_splited):\n",
    "\n",
    "    # figure\n",
    "    fig = plt.figure()\n",
    "    images_plt = []\n",
    "        \n",
    "    for j in range(len(split_)):\n",
    "        im = mpimg.imread(os.path.join(folder_temp, f'temp_{counter}.png'))\n",
    "        images.append(im)\n",
    "        images_plt.append([plt.imshow(im, animated=True)])\n",
    "        plt.axis('off')\n",
    "        counter += 1\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "# visualize\n",
    "images_numpy = np.array(images)\n",
    "image_grid = gallery(images_numpy, ncols=splitedSize)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(image_grid)\n",
    "plt.close()\n",
    "\n",
    "# 1st row: linear interpolation\n",
    "# 2nd row: geodesic interpolation using Euclidean metric\n",
    "# 3rd row: geodesic interpolation using Fisher information metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Can you explain how the shape of point cloud changes in each interpolation? What is the difference between geodesic interpolation with Euclidean metric and Fisher information metric?\n",
    "(answer here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMF_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
