{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 4, Problem 6\n",
    "\n",
    "In this exercise, you will explore the invariances that can be helpful for classifying point cloud data.\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "### Problem Definition\n",
    "\n",
    "#### Point Cloud Classification\n",
    "\n",
    "- Point cloud data is represented as a set $x = \\{ x_i \\in \\mathbb{R}^3 \\}_{i=1}^N$, where $N$ is the number of points.\n",
    "Denote the space of point clouds by $X$.\n",
    "- The objective is to investigate the invariances of a classification model $F: X \\rightarrow \\mathbb{R}^K$, where $y \\in \\mathbb{R}^K$ represents the classification logits for $K$ classes.\n",
    "\n",
    "#### Invariances in the Point Cloud Classification Task\n",
    "\n",
    "- Although a set does not have an inherent order of elements, a point cloud is represented as a list $x = [x_i]_{i=1}^N$ in computers.\n",
    "Thus, the model should be invariant to permutations of the elements in the list to effectively treat it as a set.\n",
    "- $\\mathbb{R}^3$-invariance, which ensures that translating the point cloud in 3D does not affect the classification output, would also be helpful for this classification task.\n",
    "- $\\mathrm{SO}(3)$-invariance, which ensures that rotating the point cloud in 3D does not affect the classification output, would be helpful for this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Dependency and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.dgcnn import DGCNN_cls, knn\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "num_pts = 1024      # N\n",
    "num_classes = 16    # K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Load point cloud data\n",
    "\n",
    "Load one point cloud data from the ShapeNet [1] dataset and downsample it to contain $N$ points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('ShapeNet/02691156/1a04e3eab45ca15dd86060f189eb133.txt')\n",
    "\n",
    "x = torch.Tensor(data[:num_pts, :3]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Group actions\n",
    "\n",
    "The elements and group actions of permutation, translation, and rotation groups are defined as follows:\n",
    "\n",
    "(1) Permutation\n",
    "\n",
    "- An element of the permutation group is represented as a list $\\sigma = [\\sigma_i \\in \\mathbb{N}]_{i=1}^N$ where $1 \\leq \\sigma_i \\leq N$ and $\\sigma_i \\neq \\sigma_j$ for $i \\neq j$.\n",
    "- The action of $\\sigma$ on $x = [x_1, \\cdots, x_N]$ is defined as follows:\n",
    "$$\\sigma \\cdot x = [x_{\\sigma_1}, \\cdots, x_{\\sigma_N}]$$\n",
    "\n",
    "(2) Translation\n",
    "\n",
    "- An element of the translation group is represented as a matrix $p \\in \\mathbb{R}^3$.\n",
    "- The action of $p$ on $x = [x_1, \\cdots, x_N]$ is defined as follows:\n",
    "$$p \\cdot x = [x_1 + p, \\cdots, x_N + p]$$\n",
    "\n",
    "(2) Rotation\n",
    "\n",
    "- An element of the rotation group is represented as a matrix $R \\in \\mathrm{SO}(3)$.\n",
    "- The action of $R$ on $x = [x_1, \\cdots, x_N]$ is defined as follows:\n",
    "$$R \\cdot x = [R x_1, \\cdots, R x_N]$$\n",
    "\n",
    "<b>Q. Implement functions to perform the group actions for each group.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_perm_x(x, sigma):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - x: torch.Tensor of shape (N, 3) representing the point cloud\n",
    "    - sigma: torch.Tensor of shape (N,) representing the permutation indices\n",
    "\n",
    "    Returns:\n",
    "    - x_perm: torch.Tensor of shape (N, 3) representing the permuted point cloud\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################\n",
    "    ####### YOUR CODE HERE #######\n",
    "    ######## x_perm = ... ########\n",
    "    ##############################\n",
    "\n",
    "    return x_perm\n",
    "\n",
    "def action_trans_x(x, p):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - x: torch.Tensor of shape (N, 3) representing the point cloud\n",
    "    - p: torch.Tensor of shape (3,) representing the translation vector\n",
    "\n",
    "    Returns:\n",
    "    - x_trans: torch.Tensor of shape (N, 3) representing the translated point cloud\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################\n",
    "    ####### YOUR CODE HERE #######\n",
    "    ####### x_trans = ... ########\n",
    "    ##############################\n",
    "\n",
    "    return x_trans\n",
    "\n",
    "def action_rot_x(x, R):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - x: torch.Tensor of shape (N, 3) representing the point cloud\n",
    "    - R: torch.Tensor of shape (3, 3) representing the rotation matrix\n",
    "\n",
    "    Returns:\n",
    "    - x_rot: torch.Tensor of shape (N, 3) representing the rotated point cloud\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################\n",
    "    ####### YOUR CODE HERE #######\n",
    "    ######### x_rot = ... ########\n",
    "    ##############################\n",
    "\n",
    "    return x_rot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the group action functions are implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = torch.load('assets/sigma.pt', weights_only=True).to(device)\n",
    "R = torch.load('assets/R.pt', weights_only=True).to(device)\n",
    "p = torch.load('assets/p.pt', weights_only=True).to(device)\n",
    "\n",
    "assert torch.allclose(action_perm_x(x, sigma), torch.load('assets/x_perm.pt', weights_only=True).to(device))\n",
    "assert torch.allclose(action_rot_x(x, R), torch.load('assets/x_rot.pt', weights_only=True).to(device))\n",
    "assert torch.allclose(action_trans_x(x, p), torch.load('assets/x_trans.pt', weights_only=True).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Build classification model\n",
    "\n",
    "First, we utilize DGCNN [2] as point cloud classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = DGCNN_cls(k=20, num_classes=num_classes).to(device)\n",
    "model_1.eval()    # Set model to evaluation mode to avoid batchnorm issues with single-batch inputs in training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get classification logits of the point cloud by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Check invariances\n",
    "\n",
    "For a model $F$ to be invariant to a group $G$, it must satisfy the following condition:\n",
    "$$F(g \\cdot x) = F(x) \\quad \\text{for all } g \\in G$$\n",
    "\n",
    "<b>Q. Implement functions to check if the provided model is invariant to permutations, translations, and rotations.</b>\n",
    "(Hint: You may find `torch.allclose` useful.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_perm_inv_model(model, x, sigma):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - model: nn.Module representing the model\n",
    "    - x: torch.Tensor of shape (N, 3) representing the point cloud\n",
    "    - sigma: torch.Tensor of shape (N,) representing the permutation indices\n",
    "\n",
    "    Returns:\n",
    "    - is_perm_inv: bool representing whether the model is permutation invariant\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################\n",
    "    ####### YOUR CODE HERE #######\n",
    "    ###### is_perm_inv = ... #####\n",
    "    ##############################\n",
    "\n",
    "    return is_perm_inv\n",
    "\n",
    "def check_trans_inv_model(model, x, p):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - model: nn.Module representing the model\n",
    "    - x: torch.Tensor of shape (N, 3) representing the point cloud\n",
    "    - p: torch.Tensor of shape (3,) representing the translation vector\n",
    "\n",
    "    Returns:\n",
    "    - is_trans_inv: bool representing whether the model is translation invariant\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################\n",
    "    ####### YOUR CODE HERE #######\n",
    "    ##### is_trans_inv = ... #####\n",
    "    ##############################\n",
    "\n",
    "    return is_trans_inv\n",
    "\n",
    "def check_rot_inv_model(model, x, R):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - model: nn.Module representing the model\n",
    "    - x: torch.Tensor of shape (N, 3) representing the point cloud\n",
    "    - R: torch.Tensor of shape (3, 3) representing the rotation matrix\n",
    "\n",
    "    Returns:\n",
    "    - is_rot_inv: bool representing whether the model is rotation invariant\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################\n",
    "    ####### YOUR CODE HERE #######\n",
    "    ###### is_rot_inv = ... ######\n",
    "    ##############################\n",
    "\n",
    "    return is_rot_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if DGCNN is permutation, translation, and rotation invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_perm_inv = check_perm_inv_model(model_1, x, sigma)\n",
    "is_trans_inv = check_trans_inv_model(model_1, x, p)\n",
    "is_rot_inv = check_rot_inv_model(model_1, x, R)\n",
    "\n",
    "print(f\"DGCNN is{' ' if is_perm_inv else ' NOT '}permutation invariant.\")\n",
    "print(f\"DGCNN is{' ' if is_trans_inv else ' NOT '}translation invariant.\")\n",
    "print(f\"DGCNN is{' ' if is_rot_inv else ' NOT '}rotation invariant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Incorporate $\\mathbb{R}^3$-invariance through canonicalization\n",
    "\n",
    "Using a mapping $\\bar{p}: X \\rightarrow \\mathbb{R}^3$ that satisfies $\\bar{p}(p \\cdot x) = p \\cdot \\bar{p}(x)$ for all $x \\in X$ and $p \\in \\mathbb{R}^3$, we can construct an $\\mathbb{R}^3$-invariant model $\\hat{F}$ from a  non-$\\mathbb{R}^3$-invariant model $F$ as follows:\n",
    "$$\\hat{F}(x) = F(\\bar{p}(x)^{-1} \\cdot x)$$\n",
    "where $\\bar{p}(x)^{-1}$ is not the inverse function of $\\bar{p}$, but rather the inverse of the group element output by $\\bar{p}(x)$. For instance, since $\\bar{p}(x)$ outputs a translation vector, $\\bar{p}(x)^{-1} = -\\bar{p}(x)$.\n",
    "\n",
    "Here, the mapping $\\bar{p}$ transforms the input into a standard canonical form, and is the key to turning a non-invariant model $F$ into $\\mathbb{R}^3$-invariant model.\n",
    "\n",
    "<b>Q. Construct $\\bar{p}$ that satisfies the required condition.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithCanonicalization:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, x):\n",
    "        p_bar = self._p_bar(x)\n",
    "\n",
    "        out = self.model(action_trans_x(x, -p_bar))   # Inverse of p_bar is -p_bar\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _p_bar(self, x):\n",
    "        ##############################\n",
    "        ####### YOUR CODE HERE #######\n",
    "        ######## p_bar = ... #########\n",
    "        ##############################\n",
    "\n",
    "        return p_bar\n",
    "\n",
    "model_2 = ModelWithCanonicalization(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if DGCNN with canonicalization is permutation, translation, and rotation invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_perm_inv = check_perm_inv_model(model_2, x, sigma)\n",
    "is_trans_inv = check_trans_inv_model(model_2, x, p)\n",
    "is_rot_inv = check_rot_inv_model(model_2, x, R)\n",
    "\n",
    "print(f\"DGCNN with canonicalization is{' ' if is_perm_inv else ' NOT '}permutation invariant.\")\n",
    "print(f\"DGCNN with canonicalization is{' ' if is_trans_inv else ' NOT '}translation invariant.\")\n",
    "print(f\"DGCNN with canonicalization is{' ' if is_rot_inv else ' NOT '}rotation invariant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Incorporate $\\mathrm{SO}(3)$-invariance through network architecture\n",
    "\n",
    "Instead of using canonicalization, we can design the network architecture itself to be equivariant to group actions.\n",
    "\n",
    "Vector Neurons (VNs) [3] are a network architecture specifically designed to achieve $\\mathrm{SO}(3)$-equivariance with point cloud data.\n",
    "\n",
    "In this section, we will implement the basic linear layers of VNs.\n",
    "\n",
    "#### Feature of Vector Neurons and group action of $\\mathrm{SO}(3)$\n",
    "\n",
    "VNs represent $i$-th point with a <em>vector-list feature</em> $\\boldsymbol{V} \\in \\mathbb{R}^{C \\times 3}$ which is a list of $C$ 3D vectors, resulting in vector-list features\n",
    " $\\mathcal{V} = \\{ \\boldsymbol{V}_1, \\cdots, \\boldsymbol{V}_N \\} \\in \\mathbb{R}^{N \\times C \\times 3}$.\n",
    "\n",
    "For vector-list features $\\mathcal{V}$, an element $R$ of the rotation group $\\mathrm{SO}(3)$ acts as follows:\n",
    "$$R \\cdot \\mathcal{V} = \\mathcal{V} R^T$$\n",
    "\n",
    "<b>Q. Implement functions of group action of $\\mathrm{SO}(3)$.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_rot_calV(calV, R):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - calV: torch.Tensor of shape (B, N, C, 3) representing the vector-list features (B: batch size, N: number of points, C: number of channels)\n",
    "    - R: torch.Tensor of shape (3, 3) representing the rotation matrix\n",
    "\n",
    "    Returns:\n",
    "    - calV_rot: torch.Tensor of shape (B, N, C, 3) representing the rotated vector-list features\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################\n",
    "    ####### YOUR CODE HERE #######\n",
    "    ####### calV_rot = ... #######\n",
    "    ##############################\n",
    "\n",
    "    return calV_rot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the group action functions is implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calV = torch.load('assets/calV.pt', weights_only=True).to(device)\n",
    "\n",
    "assert torch.allclose(action_rot_calV(calV, R), torch.load('assets/calV_rot.pt', weights_only=True).to(device), atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\mathrm{SO}(3)$-equivariance of VN layers\n",
    "\n",
    "The $\\mathrm{SO}(3)$-equivariance of the VN architecture is achieved by ensuring that each VN layer is $\\mathrm{SO}(3)$-equivariant.\n",
    "\n",
    "Given the number of input and output channels $C$ and $C'$, a VN layer $f: \\mathbb{R}^{N \\times C \\times 3} \\rightarrow \\mathbb{R}^{N \\times C' \\times 3}$ must satisfy the following condition to be $\\mathrm{SO}(3)$-equivariant:\n",
    "$$f(R \\cdot \\mathcal{V}) = R \\cdot f(\\mathcal{V}) \\quad \\text{for all } \\mathcal{V} \\in \\mathbb{R}^{N \\times C \\times 3} \\text{ and } R \\in \\mathrm{SO}(3)$$\n",
    "\n",
    "<b>Q. Implement functions to verify if the provided VN layer is $\\mathrm{SO}(3)$-equivariant.\n",
    "Use `torch.allclose` with the parameter `atol=1e-6`.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rot_equiv_VN_layer(layer, calV, R):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - layer: nn.Module representing the VN layer\n",
    "    - calV: torch.Tensor of shape (B, N, C, 3) representing the vector-list features\n",
    "    - R: torch.Tensor of shape (3, 3) representing the rotation matrix\n",
    "\n",
    "    Returns:\n",
    "    - is_rot_equiv: bool representing whether the provided VN layer is rotation equivariant\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################\n",
    "    ####### YOUR CODE HERE #######\n",
    "    ##### is_rot_equiv = ... #####\n",
    "    ##############################\n",
    "\n",
    "    return is_rot_equiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the provided VN-BatchNorm layer is $\\mathrm{SO}(3)$-equivariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "\n",
    "\n",
    "class VNBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        if dim == 3 or dim == 4:\n",
    "            self.bn = nn.BatchNorm1d(num_features)\n",
    "        elif dim == 5:\n",
    "            self.bn = nn.BatchNorm2d(num_features)\n",
    "    \n",
    "    def forward(self, calV):\n",
    "        '''\n",
    "        calV: torch.Tensor of shape (B, N, C, 3) representing the vector-list features\n",
    "        '''\n",
    "        calV = calV.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        norm = torch.norm(calV, dim=2) + EPS\n",
    "        norm_bn = self.bn(norm)\n",
    "        norm = norm.unsqueeze(2)\n",
    "        norm_bn = norm_bn.unsqueeze(2)\n",
    "        out = calV / norm * norm_bn\n",
    "\n",
    "        out = out.permute(0, 3, 1, 2).contiguous()\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "VN_BN_layer = VNBatchNorm(64, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_rot_equiv = check_rot_equiv_VN_layer(VN_BN_layer, calV, R)\n",
    "\n",
    "print(f\"VN-BatchNorm layer is{' ' if is_perm_inv else ' NOT '}rotation equivariant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement VN-Linear layer\n",
    "\n",
    "For a given weight matrix $\\mathbf{W} \\in \\mathbb{R}^{C' \\times C}$, the operation of the VN-Linear layer $f_\\text{lin}(\\cdot;\\mathbf{W})$ is defined as follows:\n",
    "$$f_\\text{lin}(\\{ \\boldsymbol{V}_1, \\cdots, \\boldsymbol{V}_N \\}; \\mathbf{W}) = \\{ \\mathbf{W} \\boldsymbol{V}_1, \\cdots, \\mathbf{W} \\boldsymbol{V}_N \\}$$\n",
    "\n",
    "<b>Q. Implement the forward function to perform the operation of the VN-Linear layer.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNLinear(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W = torch.nn.Parameter(torch.randn(out_channels, in_channels)) # torch.Tensor of shape (C', C) representing weight matrix\n",
    "    \n",
    "    def forward(self, calV):\n",
    "        '''\n",
    "        Parameters:\n",
    "        - calV: torch.Tensor of shape (B, N, C, 3) representing the vector-list features\n",
    "\n",
    "        Returns:\n",
    "        - out: torch.Tensor of shape (B, N, C', 3) representing the output vector-list features\n",
    "        '''\n",
    "        ##############################\n",
    "        ####### YOUR CODE HERE #######\n",
    "        ########## out = ... #########\n",
    "        ##############################\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "VN_Linear_layer = VNLinear(64, 128).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the implemented VN-Linear layer is $\\mathrm{SO}(3)$-equivariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_rot_equiv = check_rot_equiv_VN_layer(VN_Linear_layer, calV, R)\n",
    "\n",
    "print(f\"The implemented VN-Linear layer is{' ' if is_perm_inv else ' NOT '}rotation equivariant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete architecture of VN-DGCNN, which incorporates VNs into DGCNN, is structured as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNBatchNorm2(nn.Module):\n",
    "    def __init__(self, num_features, dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        if dim == 3 or dim == 4:\n",
    "            self.bn = nn.BatchNorm1d(num_features)\n",
    "        elif dim == 5:\n",
    "            self.bn = nn.BatchNorm2d(num_features)\n",
    "\n",
    "    def forward(self, calV):\n",
    "        '''\n",
    "        calV: torch.Tensor of shape (B, C, 3, N, ...) representing the vector-list features\n",
    "        '''\n",
    "        norm = torch.norm(calV, dim=2) + EPS\n",
    "        norm_bn = self.bn(norm)\n",
    "        norm = norm.unsqueeze(2)\n",
    "        norm_bn = norm_bn.unsqueeze(2)\n",
    "        calV = calV / norm * norm_bn\n",
    "\n",
    "        return calV\n",
    "\n",
    "\n",
    "class VNLinearLeakyReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dim=5, share_nonlinearity=False, negative_slope=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "        self.linear = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.batchnorm = VNBatchNorm2(out_channels, dim=dim)\n",
    "\n",
    "        if share_nonlinearity == True:\n",
    "            self.map_to_dir = nn.Linear(in_channels, 1, bias=False)\n",
    "        else:\n",
    "            self.map_to_dir = nn.Linear(in_channels, out_channels, bias=False)\n",
    "\n",
    "    def forward(self, calV):\n",
    "        '''\n",
    "        calV: torch.Tensor of shape (B, C, 3, N, ...) representing the vector-list features\n",
    "        '''\n",
    "        # Linear\n",
    "        p = self.linear(calV.transpose(1, -1)).transpose(1, -1)\n",
    "\n",
    "        # BatchNorm\n",
    "        p = self.batchnorm(p)\n",
    "\n",
    "        # LeakyReLU\n",
    "        d = self.map_to_dir(calV.transpose(1, -1)).transpose(1, -1)\n",
    "        dotprod = (p * d).sum(2, keepdims=True)\n",
    "        mask = (dotprod >= 0).float()\n",
    "        d_norm_sq = (d * d).sum(2, keepdims=True)\n",
    "        x_out = self.negative_slope * p + (1 - self.negative_slope) * (mask * p + (1 - mask) * (p - (dotprod / (d_norm_sq + EPS)) * d))\n",
    "\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class VNStdFeature(nn.Module):\n",
    "    def __init__(self, in_channels, dim=4, normalize_frame=False, share_nonlinearity=False, negative_slope=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.normalize_frame = normalize_frame\n",
    "\n",
    "        self.vn1 = VNLinearLeakyReLU(in_channels, in_channels//2, dim=dim, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
    "        self.vn2 = VNLinearLeakyReLU(in_channels//2, in_channels//4, dim=dim, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
    "\n",
    "        self.vn_lin = nn.Linear(in_channels//4, 3, bias=False)\n",
    "\n",
    "    def forward(self, calV):\n",
    "        '''\n",
    "        calV: torch.Tensor of shape (B, C, 3, N) representing the vector-list features\n",
    "        '''\n",
    "        z0 = calV\n",
    "        z0 = self.vn1(z0)\n",
    "        z0 = self.vn2(z0)\n",
    "        z0 = self.vn_lin(z0.transpose(1, -1)).transpose(1, -1)\n",
    "\n",
    "        if self.normalize_frame:\n",
    "            # make z0 orthogonal. u2 = v2 - proj_u1(v2)\n",
    "            v1 = z0[:,0,:]\n",
    "            v1_norm = torch.sqrt((v1*v1).sum(1, keepdims=True))\n",
    "            u1 = v1 / (v1_norm+EPS)\n",
    "            v2 = z0[:,1,:]\n",
    "            v2 = v2 - (v2*u1).sum(1, keepdims=True)*u1\n",
    "            v2_norm = torch.sqrt((v2*v2).sum(1, keepdims=True))\n",
    "            u2 = v2 / (v2_norm+EPS)\n",
    "\n",
    "            # compute the cross product of the two output vectors        \n",
    "            u3 = torch.cross(u1, u2)\n",
    "            z0 = torch.stack([u1, u2, u3], dim=1).transpose(1, 2)\n",
    "        else:\n",
    "            z0 = z0.transpose(1, 2)\n",
    "\n",
    "        if self.dim == 4:\n",
    "            x_std = torch.einsum('bijm,bjkm->bikm', calV, z0)\n",
    "        elif self.dim == 3:\n",
    "            x_std = torch.einsum('bij,bjk->bik', calV, z0)\n",
    "        elif self.dim == 5:\n",
    "            x_std = torch.einsum('bijmn,bjkmn->bikmn', calV, z0)\n",
    "\n",
    "        return x_std, z0\n",
    "\n",
    "\n",
    "class VN_DGCNN_cls(nn.Module):\n",
    "    def __init__(self, k, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "        self.conv1 = VNLinearLeakyReLU(2, 64//3)\n",
    "        self.conv2 = VNLinearLeakyReLU(64//3*2, 64//3)\n",
    "        self.conv3 = VNLinearLeakyReLU(64//3*2, 128//3)\n",
    "        self.conv4 = VNLinearLeakyReLU(128//3*2, 256//3)\n",
    "\n",
    "        self.conv5 = VNLinearLeakyReLU(256//3+128//3+64//3*2, 1024//3, dim=4, share_nonlinearity=True)\n",
    "\n",
    "        self.std_feature = VNStdFeature(1024//3*2, dim=4, normalize_frame=False)\n",
    "        self.linear1 = nn.Linear((1024//3)*12, 512)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dp1 = nn.Dropout(p=0.5)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        self.linear3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.T.unsqueeze(0)\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = get_graph_feature(x, k=self.k)\n",
    "        x = self.conv1(x)\n",
    "        x1 = x.mean(dim=-1, keepdim=False)\n",
    "\n",
    "        x = get_graph_feature(x1, k=self.k)\n",
    "        x = self.conv2(x)\n",
    "        x2 = x.mean(dim=-1, keepdim=False)\n",
    "\n",
    "        x = get_graph_feature(x2, k=self.k)\n",
    "        x = self.conv3(x)\n",
    "        x3 = x.mean(dim=-1, keepdim=False)\n",
    "\n",
    "        x = get_graph_feature(x3, k=self.k)\n",
    "        x = self.conv4(x)\n",
    "        x4 = x.mean(dim=-1, keepdim=False)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        num_points = x.size(-1)\n",
    "        x_mean = x.mean(dim=-1, keepdim=True).expand(x.size())\n",
    "        x = torch.cat((x, x_mean), 1)\n",
    "        x, _ = self.std_feature(x)\n",
    "        x = x.view(batch_size, -1, num_points)\n",
    "\n",
    "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
    "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), negative_slope=0.2)\n",
    "        x = self.dp1(x)\n",
    "        x = F.leaky_relu(self.bn2(self.linear2(x)), negative_slope=0.2)\n",
    "        x = self.dp2(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_graph_feature(x, k=20, idx=None, x_coord=None):\n",
    "    batch_size = x.size(0)\n",
    "    num_points = x.size(3)\n",
    "    x = x.view(batch_size, -1, num_points)\n",
    "    if idx is None:\n",
    "        if x_coord is None: # dynamic knn graph\n",
    "            idx = knn(x, k=k)\n",
    "        else:          # fixed knn graph with input point coordinates\n",
    "            idx = knn(x_coord, k=k)\n",
    "\n",
    "    idx_base = torch.arange(0, batch_size).to(idx).view(-1, 1, 1)*num_points\n",
    "\n",
    "    idx = idx + idx_base\n",
    "\n",
    "    idx = idx.view(-1)\n",
    "\n",
    "    _, num_dims, _ = x.size()\n",
    "    num_dims = num_dims // 3\n",
    "\n",
    "    x = x.transpose(2, 1).contiguous()\n",
    "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
    "    feature = feature.view(batch_size, num_points, k, num_dims, 3) \n",
    "    x = x.view(batch_size, num_points, 1, num_dims, 3).repeat(1, 1, k, 1, 1)\n",
    "\n",
    "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 4, 1, 2).contiguous()\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build VN-DGCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = VN_DGCNN_cls(k=20, num_classes=num_classes).to(device)\n",
    "model_3.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if VN-DGCNN is permutation, translation, and rotation invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_perm_inv = check_perm_inv_model(model_3, x, sigma)\n",
    "is_trans_inv = check_trans_inv_model(model_3, x, p)\n",
    "is_rot_inv = check_rot_inv_model(model_3, x, R)\n",
    "\n",
    "print(f\"VN-DGCNN is{' ' if is_perm_inv else ' NOT '}permutation invariant.\")\n",
    "print(f\"VN-DGCNN is{' ' if is_trans_inv else ' NOT '}translation invariant.\")\n",
    "print(f\"VN-DGCNN is{' ' if is_rot_inv else ' NOT '}rotation invariant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Final model with permutation, translation, and rotation invariances.\n",
    "\n",
    "The final model incorporates permutation, translation, and rotation invariances by achieving $\\mathbb{R}^3$-invariance in the VN-DGCNN model through canonicalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = ModelWithCanonicalization(model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if VN-DGCNN with canonicalization is permutation, translation, and rotation invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_perm_inv = check_perm_inv_model(model_4, x, sigma)\n",
    "is_trans_inv = check_trans_inv_model(model_4, x, p)\n",
    "is_rot_inv = check_rot_inv_model(model_4, x, R)\n",
    "\n",
    "print(f\"VN-DGCNN with canonicalization is{' ' if is_perm_inv else ' NOT '}permutation invariant.\")\n",
    "print(f\"VN-DGCNN with canonicalization is{' ' if is_trans_inv else ' NOT '}translation invariant.\")\n",
    "print(f\"VN-DGCNN with canonicalization is{' ' if is_rot_inv else ' NOT '}rotation invariant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Advantages of Equivariant Models\n",
    "\n",
    "<b>Q. In general, what advantages do equivariant models have compared to non-equivariant models?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, F. Yu, ShapeNet: An Information-Rich 3D Model Repository, arXiv.\n",
    "\n",
    "[2] Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, J. M. Solomon, Dynamic Graph CNN for Learning on Point Clouds, TOG 2019.\n",
    "\n",
    "[3] C. Deng, O. Litany, Y. Duan, A. Poulenard, A. Tagliasacchi, L. Guibas, Vector Neurons: A General Framework for SO(3)-Equivariant Networks, ICCV 2021."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gm4hdda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
